{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "177HW3cuRH7g",
        "outputId": "765d8f29-b103-4060-e514-9163f00cf712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.functional import pad\n",
        "\n",
        "raw_data = pd.read_csv(r\"/content/drive/MyDrive/483/1_ETHUSDT_1.1.2018-1.2.2024_1hour.csv\", header=None)\n",
        "raw_data.columns = ['date', 'open', 'high', 'low', 'close', 'volume'] + list(raw_data.columns[6:])\n",
        "raw_data.drop(raw_data.columns[6:], axis=1, inplace=True)\n",
        "raw_data['date'] = pd.to_datetime(raw_data['date'])\n",
        "raw_data.set_index('date', inplace=True)\n",
        "\n",
        "# Create a new column 'next_10_close' that contains the next 10 'close' values\n",
        "next_10_close_values = [list(raw_data['close'].iloc[i+1:i+11]) for i in range(len(raw_data)-10)] + [None]*10\n",
        "raw_data['next_10_close'] = next_10_close_values\n",
        "raw_data = raw_data.dropna()\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "normalized_data = pd.DataFrame(scaler.fit_transform(raw_data.drop(columns='next_10_close')), columns=raw_data.drop(columns='next_10_close').columns, index=raw_data.index)\n",
        "\n",
        "# Normalize 'next_10_close' separately\n",
        "next_10_close_scaler = MinMaxScaler()\n",
        "\n",
        "# Flatten the list of lists and reshape it to fit the scaler\n",
        "flattened = np.array([val for sublist in raw_data['next_10_close'].tolist() for val in sublist]).reshape(-1, 1)\n",
        "\n",
        "next_10_close_scaler.fit(flattened)\n",
        "\n",
        "next_10_close = raw_data['next_10_close'].apply(lambda x: [next_10_close_scaler.transform(np.array(val).reshape(-1, 1))[0][0] for val in x])\n",
        "\n",
        "normalized_data = pd.concat([normalized_data, next_10_close.rename('next_10_close')], axis=1)\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, sequences, targets, seq_length):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.sequences.shape[0] - self.seq_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = torch.tensor(self.sequences[index:index+self.seq_length].values, dtype=torch.float32)\n",
        "        target = torch.tensor(self.targets[index + self.seq_length], dtype=torch.float32)\n",
        "        if target.dim() == 0:\n",
        "            target = target.view(1)\n",
        "        if len(target) < 10:\n",
        "            return None\n",
        "        return sequence, target\n",
        "\n",
        "features = normalized_data[['open', 'high', 'low', 'close', 'volume']]\n",
        "targets = normalized_data['next_10_close']\n",
        "seq_length = 24\n",
        "dataset = TimeSeriesDataset(features, targets, seq_length)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        if d_model % 2 == 0:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)[:, :-1]\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x) -> torch.Tensor:\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=ninp, nhead=nhead, dim_feedforward=nhid, dropout=dropout, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=nlayers)\n",
        "        self.decoder = nn.Linear(ninp, 10)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "# Define the size of each split\n",
        "train_size = int(len(dataset) * 0.7)\n",
        "val_size = int(len(dataset) * 0.15)\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "# Split the data\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "class FilteredDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = [item for item in dataset if item is not None]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.dataset[index]\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=24, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=24, shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=24, shuffle=False, drop_last=True)\n",
        "\n",
        "model = TransformerModel(ninp=5, nhead=5, nhid=256, nlayers=4, dropout=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ec3rHSpA5uX8",
        "outputId": "af5faf76-70a5-4ed0-ce37-f73c68137c94"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         open      high       low     close    volume  \\\n",
              "date                                                                    \n",
              "2017-12-31 19:00:00  0.136596  0.136168  0.134327  0.135470  0.004270   \n",
              "2017-12-31 20:00:00  0.135337  0.135641  0.133647  0.133444  0.004675   \n",
              "2017-12-31 21:00:00  0.133377  0.134335  0.133813  0.134720  0.004392   \n",
              "2017-12-31 22:00:00  0.134695  0.136893  0.134889  0.136914  0.004381   \n",
              "2017-12-31 23:00:00  0.137012  0.138354  0.136427  0.139080  0.004735   \n",
              "...                       ...       ...       ...       ...       ...   \n",
              "2024-01-31 05:00:00  0.467816  0.466196  0.462981  0.462129  0.063831   \n",
              "2024-01-31 06:00:00  0.462109  0.463423  0.462807  0.465524  0.039286   \n",
              "2024-01-31 07:00:00  0.465503  0.464892  0.466199  0.466444  0.025457   \n",
              "2024-01-31 08:00:00  0.466424  0.467119  0.466578  0.468188  0.030382   \n",
              "2024-01-31 09:00:00  0.468166  0.466380  0.466526  0.467040  0.034081   \n",
              "\n",
              "                                                         next_10_close  \n",
              "date                                                                    \n",
              "2017-12-31 19:00:00  [0.1334441520062797, 0.13472024581596542, 0.13...  \n",
              "2017-12-31 20:00:00  [0.13472024581596542, 0.13691353205136278, 0.1...  \n",
              "2017-12-31 21:00:00  [0.13691353205136278, 0.13907953338622406, 0.1...  \n",
              "2017-12-31 22:00:00  [0.13907953338622406, 0.1399547490418802, 0.14...  \n",
              "2017-12-31 23:00:00  [0.1399547490418802, 0.14272311702703722, 0.14...  \n",
              "...                                                                ...  \n",
              "2024-01-31 05:00:00  [0.4655244787534578, 0.46644377001767223, 0.46...  \n",
              "2024-01-31 06:00:00  [0.46644377001767223, 0.4681879048134762, 0.46...  \n",
              "2024-01-31 07:00:00  [0.4681879048134762, 0.46703984015245964, 0.47...  \n",
              "2024-01-31 08:00:00  [0.46703984015245964, 0.47166148253556484, 0.4...  \n",
              "2024-01-31 09:00:00  [0.47166148253556484, 0.47512246722663676, 0.4...  \n",
              "\n",
              "[53197 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a27a769e-5fe5-46c0-ace6-cc0df783f175\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>next_10_close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-12-31 19:00:00</th>\n",
              "      <td>0.136596</td>\n",
              "      <td>0.136168</td>\n",
              "      <td>0.134327</td>\n",
              "      <td>0.135470</td>\n",
              "      <td>0.004270</td>\n",
              "      <td>[0.1334441520062797, 0.13472024581596542, 0.13...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 20:00:00</th>\n",
              "      <td>0.135337</td>\n",
              "      <td>0.135641</td>\n",
              "      <td>0.133647</td>\n",
              "      <td>0.133444</td>\n",
              "      <td>0.004675</td>\n",
              "      <td>[0.13472024581596542, 0.13691353205136278, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 21:00:00</th>\n",
              "      <td>0.133377</td>\n",
              "      <td>0.134335</td>\n",
              "      <td>0.133813</td>\n",
              "      <td>0.134720</td>\n",
              "      <td>0.004392</td>\n",
              "      <td>[0.13691353205136278, 0.13907953338622406, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 22:00:00</th>\n",
              "      <td>0.134695</td>\n",
              "      <td>0.136893</td>\n",
              "      <td>0.134889</td>\n",
              "      <td>0.136914</td>\n",
              "      <td>0.004381</td>\n",
              "      <td>[0.13907953338622406, 0.1399547490418802, 0.14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 23:00:00</th>\n",
              "      <td>0.137012</td>\n",
              "      <td>0.138354</td>\n",
              "      <td>0.136427</td>\n",
              "      <td>0.139080</td>\n",
              "      <td>0.004735</td>\n",
              "      <td>[0.1399547490418802, 0.14272311702703722, 0.14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-31 05:00:00</th>\n",
              "      <td>0.467816</td>\n",
              "      <td>0.466196</td>\n",
              "      <td>0.462981</td>\n",
              "      <td>0.462129</td>\n",
              "      <td>0.063831</td>\n",
              "      <td>[0.4655244787534578, 0.46644377001767223, 0.46...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-31 06:00:00</th>\n",
              "      <td>0.462109</td>\n",
              "      <td>0.463423</td>\n",
              "      <td>0.462807</td>\n",
              "      <td>0.465524</td>\n",
              "      <td>0.039286</td>\n",
              "      <td>[0.46644377001767223, 0.4681879048134762, 0.46...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-31 07:00:00</th>\n",
              "      <td>0.465503</td>\n",
              "      <td>0.464892</td>\n",
              "      <td>0.466199</td>\n",
              "      <td>0.466444</td>\n",
              "      <td>0.025457</td>\n",
              "      <td>[0.4681879048134762, 0.46703984015245964, 0.47...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-31 08:00:00</th>\n",
              "      <td>0.466424</td>\n",
              "      <td>0.467119</td>\n",
              "      <td>0.466578</td>\n",
              "      <td>0.468188</td>\n",
              "      <td>0.030382</td>\n",
              "      <td>[0.46703984015245964, 0.47166148253556484, 0.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-31 09:00:00</th>\n",
              "      <td>0.468166</td>\n",
              "      <td>0.466380</td>\n",
              "      <td>0.466526</td>\n",
              "      <td>0.467040</td>\n",
              "      <td>0.034081</td>\n",
              "      <td>[0.47166148253556484, 0.47512246722663676, 0.4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53197 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a27a769e-5fe5-46c0-ace6-cc0df783f175')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a27a769e-5fe5-46c0-ace6-cc0df783f175 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a27a769e-5fe5-46c0-ace6-cc0df783f175');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-47aff4fa-f778-4af3-ae7d-2d15186ee259\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47aff4fa-f778-4af3-ae7d-2d15186ee259')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-47aff4fa-f778-4af3-ae7d-2d15186ee259 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4a963fc3-3414-4bf1-829e-94806fb402ce\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('normalized_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4a963fc3-3414-4bf1-829e-94806fb402ce button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('normalized_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "normalized_data",
              "summary": "{\n  \"name\": \"normalized_data\",\n  \"rows\": 53197,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2017-12-31 19:00:00\",\n        \"max\": \"2024-01-31 09:00:00\",\n        \"num_unique_values\": 53191,\n        \"samples\": [\n          \"2023-02-18 08:00:00\",\n          \"2021-04-17 02:00:00\",\n          \"2023-04-19 06:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23617386265748708,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 43979,\n        \"samples\": [\n          0.3462279475652601,\n          0.07949160297012664,\n          0.5270862453250729\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23657133239144168,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 41687,\n        \"samples\": [\n          0.038933762447623324,\n          0.3739250373559315,\n          0.2853596096174544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2353276734469785,\n        \"min\": 0.0,\n        \"max\": 1.0000000000000002,\n        \"num_unique_values\": 41949,\n        \"samples\": [\n          0.010697899566443576,\n          0.3824009765542788,\n          0.05339689354716505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23618726111033922,\n        \"min\": 0.0,\n        \"max\": 1.0000000000000002,\n        \"num_unique_values\": 43960,\n        \"samples\": [\n          0.18409542159369002,\n          0.37658619719847036,\n          0.37177356051161287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0560950484406066,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 53194,\n        \"samples\": [\n          0.09812162832988477,\n          0.03472140447957978,\n          0.050607328963819594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"next_10_close\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, epochs=30):\n",
        "    model.train()\n",
        "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        total_train_loss = 0\n",
        "        for seq, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(seq)[-10:].squeeze()\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "        scheduler.step()\n",
        "\n",
        "        val_loss = evaluate(model, criterion, val_loader)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/483/best_model.pth')\n",
        "            print(f'Saved new best model at epoch {epoch+1}')\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {total_train_loss / len(train_loader)}, Validation Loss: {val_loss}')\n",
        "\n",
        "def evaluate(model, criterion, data_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for seq, target in data_loader:\n",
        "            output = model(seq)[-10:].squeeze()\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, epochs=10)\n",
        "\n",
        "def load_model(model_path, model):\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def predict_and_evaluate(model, data_loader, criterion):\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for seq, target in data_loader:\n",
        "            output = model(seq)[-10:].squeeze()\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "            predictions.extend(output.tolist())\n",
        "            actuals.extend(target.tolist())\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    return average_loss, predictions, actuals\n",
        "\n",
        "# model_path = '/content/drive/MyDrive/483/best_model.pth'\n",
        "# model = load_model(model_path, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-9_PAW1xP3m",
        "outputId": "636a23c4-dcde-4bad-e778-44b86f5b9cfa"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([24, 10])) that is different to the input size (torch.Size([10, 24, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model at epoch 1\n",
            "Epoch 1, Training Loss: 0.056634948215176985, Validation Loss: 0.055587945264730466\n",
            "Saved new best model at epoch 2\n",
            "Epoch 2, Training Loss: 0.0561948369888048, Validation Loss: 0.055135421247322514\n",
            "Epoch 3, Training Loss: 0.05616401759126494, Validation Loss: 0.05517468438764293\n",
            "Saved new best model at epoch 4\n",
            "Epoch 4, Training Loss: 0.05622189953803055, Validation Loss: 0.055041602571461214\n",
            "Epoch 5, Training Loss: 0.05620175637184612, Validation Loss: 0.05607232923271606\n",
            "Saved new best model at epoch 6\n",
            "Epoch 6, Training Loss: 0.056027814614917, Validation Loss: 0.055035438596169994\n",
            "Epoch 7, Training Loss: 0.05600362738534327, Validation Loss: 0.055068991612643\n",
            "Epoch 8, Training Loss: 0.0559929821435963, Validation Loss: 0.0550552348168679\n",
            "Epoch 9, Training Loss: 0.055980385982942193, Validation Loss: 0.05504336838150419\n",
            "Saved new best model at epoch 10\n",
            "Epoch 10, Training Loss: 0.05598485339432955, Validation Loss: 0.05503416782334806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_predictions, test_actuals = predict_and_evaluate(model, test_loader, criterion)\n"
      ],
      "metadata": {
        "id": "AsSjzpclkkwk"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL8-YYac_G-5",
        "outputId": "76541a15-ad2b-48d1-e1f2-528a7fab0461"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.056397126505084064"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(f\"Predicted: {test_predictions[i]}, Actual: {test_actuals[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDzSkeHl_J4E",
        "outputId": "582e69d9-bb89-4f51-ca99-9e77f9d31089"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [[0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285], [0.24939605593681335, 0.24952849745750427, 0.24960358440876007, 0.24939647316932678, 0.24962428212165833, 0.24979503452777863, 0.2498684674501419, 0.24964618682861328, 0.24974261224269867, 0.24971795082092285]], Actual: [0.12500052154064178, 0.12483681738376617, 0.126557856798172, 0.12579388916492462, 0.12598487734794617, 0.12451989203691483, 0.12358590960502625, 0.11994442343711853, 0.11854869872331619, 0.1199297308921814]\n",
            "Predicted: [[0.24939608573913574, 0.24952848255634308, 0.2496035248041153, 0.2493966519832611, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.2496464103460312, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952848255634308, 0.2496035248041153, 0.2493966519832611, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.2496464103460312, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524], [0.24939608573913574, 0.24952849745750427, 0.2496035248041153, 0.24939663708209991, 0.24962428212165833, 0.24979498982429504, 0.24986842274665833, 0.24964639544487, 0.24974261224269867, 0.24971798062324524]], Actual: [0.384939581155777, 0.3844001591205597, 0.38338223099708557, 0.38254478573799133, 0.3806978166103363, 0.3780784606933594, 0.3786766529083252, 0.37944692373275757, 0.3850612938404083, 0.38358792662620544]\n",
            "Predicted: [[0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964670836925507, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493969053030014, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964670836925507, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964670836925507, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971799552440643], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971799552440643], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971799552440643], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964670836925507, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493969202041626, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964672327041626, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493969202041626, 0.24962428212165833, 0.24979493021965027, 0.24986831843852997, 0.24964673817157745, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493969053030014, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964672327041626, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493969053030014, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964670836925507, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964670836925507, 0.24974261224269867, 0.24971801042556763], [0.24939614534378052, 0.24952848255634308, 0.24960343539714813, 0.2493968904018402, 0.24962429702281952, 0.24979493021965027, 0.24986831843852997, 0.24964669346809387, 0.24974261224269867, 0.24971801042556763]], Actual: [0.3569536507129669, 0.3549240827560425, 0.34989526867866516, 0.35048502683639526, 0.3517695367336273, 0.3504871428012848, 0.3504997193813324, 0.3506004810333252, 0.35393133759498596, 0.3567647635936737]\n",
            "Predicted: [[0.24939624965190887, 0.24952849745750427, 0.24960340559482574, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.24964682757854462, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960340559482574, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.24964682757854462, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960340559482574, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.24964682757854462, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960340559482574, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.24964682757854462, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.2496468424797058, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.2496468424797058, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939705431461334, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.249646857380867, 0.24974258244037628, 0.24971799552440643], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.24964682757854462, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.24964682757854462, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952848255634308, 0.24960337579250336, 0.24939709901809692, 0.2496243119239807, 0.2497948855161667, 0.2498682141304016, 0.24964691698551178, 0.24974259734153748, 0.24971799552440643], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939705431461334, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.2496468424797058, 0.24974258244037628, 0.24971799552440643], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.2496468424797058, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939705431461334, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.2496468424797058, 0.24974258244037628, 0.24971799552440643], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.24964682757854462, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960340559482574, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.24964682757854462, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.24964682757854462, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939705431461334, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.249646857380867, 0.24974258244037628, 0.24971799552440643], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.2496468424797058, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939705431461334, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.249646857380867, 0.24974258244037628, 0.24971799552440643], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.2496468424797058, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.2496468424797058, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.2496468424797058, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.2496468424797058, 0.24974258244037628, 0.24971798062324524], [0.24939624965190887, 0.24952849745750427, 0.24960339069366455, 0.24939703941345215, 0.2496243119239807, 0.24979490041732788, 0.2498682290315628, 0.24964682757854462, 0.24974258244037628, 0.24971798062324524]], Actual: [0.03586495295166969, 0.03590482845902443, 0.0359342135488987, 0.036225952208042145, 0.03626163303852081, 0.03624064475297928, 0.03638336434960365, 0.036372870206832886, 0.036458924412727356, 0.036410652101039886]\n",
            "Predicted: [[0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986819922924042, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986818432807922, 0.24964682757854462, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986819922924042, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939703941345215, 0.2496243268251419, 0.24979490041732788, 0.24986819922924042, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939703941345215, 0.2496243268251419, 0.24979490041732788, 0.24986819922924042, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939703941345215, 0.2496243268251419, 0.24979490041732788, 0.24986819922924042, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939703941345215, 0.2496243268251419, 0.24979490041732788, 0.24986819922924042, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986818432807922, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986818432807922, 0.24964682757854462, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986819922924042, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986818432807922, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960339069366455, 0.24939706921577454, 0.2496243268251419, 0.2497948855161667, 0.24986818432807922, 0.2496468424797058, 0.2497425675392151, 0.24971796572208405], [0.24939630925655365, 0.24952851235866547, 0.24960339069366455, 0.24939705431461334, 0.2496243268251419, 0.2497948855161667, 0.24986818432807922, 0.24964682757854462, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986818432807922, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986818432807922, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986818432807922, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960339069366455, 0.24939705431461334, 0.2496243268251419, 0.2497948855161667, 0.24986818432807922, 0.24964682757854462, 0.2497425675392151, 0.24971796572208405], [0.24939630925655365, 0.24952851235866547, 0.24960339069366455, 0.24939705431461334, 0.2496243268251419, 0.2497948855161667, 0.24986818432807922, 0.24964682757854462, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960339069366455, 0.24939705431461334, 0.2496243268251419, 0.2497948855161667, 0.24986818432807922, 0.24964682757854462, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939703941345215, 0.2496243268251419, 0.24979490041732788, 0.24986819922924042, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939703941345215, 0.2496243268251419, 0.24979490041732788, 0.24986819922924042, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960340559482574, 0.24939705431461334, 0.2496243268251419, 0.24979490041732788, 0.24986819922924042, 0.24964681267738342, 0.2497425675392151, 0.24971795082092285], [0.24939630925655365, 0.24952851235866547, 0.24960339069366455, 0.24939705431461334, 0.2496243268251419, 0.2497948855161667, 0.24986818432807922, 0.24964682757854462, 0.2497425675392151, 0.24971796572208405], [0.24939630925655365, 0.24952851235866547, 0.24960339069366455, 0.24939708411693573, 0.2496243268251419, 0.2497948855161667, 0.24986818432807922, 0.2496468722820282, 0.2497425675392151, 0.24971796572208405]], Actual: [0.23163831233978271, 0.23315787315368652, 0.2330550253391266, 0.23636698722839355, 0.23638588190078735, 0.23729467391967773, 0.23635859787464142, 0.23694416880607605, 0.23688960075378418, 0.23634180426597595]\n",
            "Predicted: [[0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939681589603424, 0.2496243268251419, 0.24979494512081146, 0.2498682588338852, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939681589603424, 0.2496243268251419, 0.24979494512081146, 0.2498682588338852, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939681589603424, 0.2496243268251419, 0.24979494512081146, 0.2498682588338852, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939681589603424, 0.2496243268251419, 0.24979494512081146, 0.2498682588338852, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682588338852, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682588338852, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682588338852, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939681589603424, 0.2496243268251419, 0.24979494512081146, 0.2498682588338852, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682588338852, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682588338852, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046], [0.24939626455307007, 0.24952852725982666, 0.2496034801006317, 0.24939680099487305, 0.2496243268251419, 0.24979494512081146, 0.2498682737350464, 0.24964651465415955, 0.2497425675392151, 0.24971792101860046]], Actual: [0.7003530263900757, 0.7071511745452881, 0.7133427262306213, 0.7197127342224121, 0.7164847254753113, 0.7179790735244751, 0.7202416062355042, 0.721022367477417, 0.7222229242324829, 0.7166127562522888]\n",
            "Predicted: [[0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971792101860046], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971792101860046], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971792101860046], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971792101860046], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971792101860046], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971792101860046], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971792101860046], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971792101860046], [0.24939611554145813, 0.24952851235866547, 0.24960356950759888, 0.24939653277397156, 0.24962429702281952, 0.24979501962661743, 0.24986842274665833, 0.24964623153209686, 0.24974259734153748, 0.24971793591976166]], Actual: [0.6016908288002014, 0.6012584567070007, 0.5995730757713318, 0.598771333694458, 0.5995395183563232, 0.6013213992118835, 0.6006141304969788, 0.5999781489372253, 0.596206545829773, 0.6021840572357178]\n",
            "Predicted: [[0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986842274665833, 0.2496463656425476, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986842274665833, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986842274665833, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986842274665833, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986842274665833, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986842274665833, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986842274665833, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986842274665833, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463507413864, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952848255634308, 0.2496035397052765, 0.24939660727977753, 0.24962426722049713, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971798062324524], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971798062324524], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952848255634308, 0.2496035397052765, 0.24939660727977753, 0.24962426722049713, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971798062324524], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971798062324524], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971796572208405], [0.24939607083797455, 0.24952849745750427, 0.2496035397052765, 0.24939660727977753, 0.24962428212165833, 0.24979500472545624, 0.24986843764781952, 0.2496463656425476, 0.24974261224269867, 0.24971796572208405]], Actual: [0.4325391352176666, 0.4331603944301605, 0.4308684468269348, 0.4331142008304596, 0.4342895746231079, 0.4315442740917206, 0.43314990401268005, 0.43090832233428955, 0.4337690472602844, 0.43453723192214966]\n",
            "Predicted: [[0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.2493968904018402, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.2493968904018402, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.2493968904018402, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.2493968904018402, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964672327041626, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.2493968904018402, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.2493968904018402, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882], [0.24939610064029694, 0.24952846765518188, 0.24960343539714813, 0.24939687550067902, 0.24962428212165833, 0.24979493021965027, 0.24986834824085236, 0.24964670836925507, 0.24974261224269867, 0.24971802532672882]], Actual: [0.03969113528728485, 0.03981916233897209, 0.039632368832826614, 0.03950643539428711, 0.039485447108745575, 0.03978348523378372, 0.03896283730864525, 0.03893135488033295, 0.038967035710811615, 0.038912467658519745]\n",
            "Predicted: [[0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979490041732788, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979490041732788, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979491531848907, 0.2498682588338852, 0.24964679777622223, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939702451229095, 0.2496243119239807, 0.24979490041732788, 0.2498682588338852, 0.24964682757854462, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939700961112976, 0.2496243119239807, 0.24979490041732788, 0.2498682588338852, 0.24964681267738342, 0.24974259734153748, 0.24971799552440643], [0.2493962049484253, 0.24952848255634308, 0.24960340559482574, 0.24939699470996857, 0.2496243119239807, 0.24979490041732788, 0.2498682588338852, 0.24964681267738342, 0.24974259734153748, 0.24971799552440643]], Actual: [0.36785921454429626, 0.36734920740127563, 0.36767661571502686, 0.3677353858947754, 0.3680942952632904, 0.36795368790626526, 0.36549803614616394, 0.363812655210495, 0.36121639609336853, 0.36073365807533264]\n"
          ]
        }
      ]
    }
  ]
}